{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "tOO-FmXlzkVo",
    "outputId": "3255802f-2013-4023-a81e-cce607a64cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
      "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.6)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain_huggingface\n",
      "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pinecone\n",
      "  Downloading pinecone-8.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pinecone_text\n",
      "  Downloading pinecone_text-0.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Collecting cohere\n",
      "  Downloading cohere-5.20.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.6.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.13.0)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2026.1.4)\n",
      "Requirement already satisfied: orjson>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.11.5)\n",
      "Collecting pinecone-plugin-assistant<4.0.0,>=3.0.1 (from pinecone)\n",
      "  Downloading pinecone_plugin_assistant-3.0.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pinecone-plugin-interface<0.1.0,>=0.0.7 (from pinecone)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
      "Collecting mmh3<5.0.0,>=4.1.0 (from pinecone_text)\n",
      "  Downloading mmh3-4.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from pinecone_text) (3.9.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pinecone_text) (1.2.1)\n",
      "Collecting types-requests<3.0.0,>=2.25.0 (from pinecone_text)\n",
      "  Downloading types_requests-2.32.4.20260107-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: pydantic-core>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.41.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.20.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.9.1->pinecone_text) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.9.1->pinecone_text) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.9.1->pinecone_text) (2025.11.3)\n",
      "Collecting packaging<26.0.0,>=23.2.0 (from langchain-core)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.6.0-py3-none-any.whl (328 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
      "Downloading pinecone-8.0.0-py3-none-any.whl (745 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m745.9/745.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_text-0.11.0-py3-none-any.whl (22 kB)\n",
      "Downloading cohere-5.20.1-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.0/319.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_assistant-3.0.1-py3-none-any.whl (280 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.9/280.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.32.4.20260107-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: mmh3, types-requests, requests, pypdf, pinecone-plugin-interface, packaging, mypy-extensions, fastavro, typing-inspect, pinecone_text, pinecone-plugin-assistant, marshmallow, pinecone, dataclasses-json, cohere, langchain-text-splitters, langchain_huggingface, langchain-classic, langchain-community\n",
      "  Attempting uninstall: mmh3\n",
      "    Found existing installation: mmh3 5.2.0\n",
      "    Uninstalling mmh3-5.2.0:\n",
      "      Successfully uninstalled mmh3-5.2.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cohere-5.20.1 dataclasses-json-0.6.7 fastavro-1.12.1 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-text-splitters-1.1.0 langchain_huggingface-1.2.0 marshmallow-3.26.2 mmh3-4.1.0 mypy-extensions-1.1.0 packaging-24.2 pinecone-8.0.0 pinecone-plugin-assistant-3.0.1 pinecone-plugin-interface-0.0.7 pinecone_text-0.11.0 pypdf-6.6.0 requests-2.32.5 types-requests-2.32.4.20260107 typing-inspect-0.9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "264845fce0ed438b873fb7f886c21360",
       "pip_warning": {
        "packages": [
         "packaging"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install langchain langchain-core langchain-community pypdf langchain_huggingface pinecone pinecone_text sentence-transformers cohere tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O4nStzNszoBn"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_.........\"\n",
    "\n",
    "pc = Pinecone()\n",
    "\n",
    "index_name = \"final-rag-trailer\"\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bpJfaW4BzpKe"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNCtZO96zquE",
    "outputId": "721b7a91-360f-4814-c41b-a7960d5be39c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "bm25 = BM25Encoder.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517,
     "referenced_widgets": [
      "4ad74d5912e04619930e0cc08ce8f39c",
      "b6b5da7827354106b88ab1316c4be5f2",
      "229c32bfe24044bdb841dc4b000b0a56",
      "49bcd3b3396b4c01bb16b1f339424445",
      "0b130c1b81a041f8b8ee42a4931b75c4",
      "90ff24a4c6a04289a955402b360807b7",
      "fc586f56c00d48ff967cea20776dafb5",
      "f216a61cf3354f0a9f224f898b6d9d26",
      "ad9fa76190164157bb3ef594f96d1fe5",
      "72dd2109816547f29e00acba7a482639",
      "7b5e1f6c5d6f4d0c83da280baf6efbe7",
      "a5ea35e6572947e1ae2f701f533ec084",
      "72b62ab4bff7483aab5362d0805eccdd",
      "834462cf1fa54378b3149242ef8ecda5",
      "db51b7a5da194ffbb5a1033835f9296c",
      "b438db2112d34076a21d02c4093109e3",
      "1ed4982d6c734e59845175d8495fd25e",
      "1b98251768c64ac38ef0b92da32a52ce",
      "b89a93a11cfb40b3a3e583f4f5115b7e",
      "37803c90e0994c3f8a94a86abda5a868",
      "ca9e4f454cf9458d931f16755d91e438",
      "cee3fa46f2174c2dbceb6dd0b7aff345",
      "0e47c19a11554cea9b93f0e2c3666776",
      "2e8b6f74c4ed4524b47f0f48aac5a84d",
      "f6d268dd87a8447a95250b0fae7270cf",
      "65f2677484a746d9993b47e342b8f7f7",
      "81da7466f3134162ab8497a1ea97b992",
      "86f65af5cf0348329200f950dcb819b2",
      "fc22ab1c157e4f559dfabe900c085832",
      "2b4b6dc81ba34d81805ba67141148f24",
      "a7b0847fcc6a4690947cd32f36d2c5c5",
      "500c2b1f2af94db395e6f1810a19bfac",
      "2aac6b8814c144149951076bd9b84465",
      "d6e0c6b5034741d8b461a1cbf3ce05ec",
      "1f7787e189f647df8e2af90a47f8747f",
      "e0eb3bfeb0854ccaafc5921747e311ad",
      "cb8387d9220c47548bf2395aa7390fe6",
      "07ef965925574b7f8b4533bc6fca7491",
      "3e347255086b41ac91dc487a95eb99bb",
      "0f25efdc1ace49e4a077a840d54a1dd9",
      "370f52157e454c18ae0b212a062c7f45",
      "2220add648e84a13b5fe89d46ea16c6a",
      "fccd20f8d4c24820b5ae84275715c7e4",
      "4bca857d1d5a48f888ff8e6ae0d5aac2",
      "79b828a9f4d64b9d9e2fcb688cee3514",
      "60bf7cdfd1be464694fbfa8cc584f785",
      "0325340cc16a4cdebbf03a09ace78aee",
      "14c16c8cff254f058f63727a857849b0",
      "a978a0fc71aa4f048549d9e8902de4a4",
      "fe19946759c14cd1a6171872a42b7713",
      "482acd4a262a44b8b90741a28561e7fd",
      "92a87190f69b470bb11b7f31aac8e1e1",
      "d8276b21419d4c2abdfe4d8ada6a7866",
      "42820c7bcd2e4c44ab494c68add97275",
      "ac6c2b23c91547a4b786dbef05e90601",
      "1b0d5106a76f4a4a9a7c6ee860a3c2cf",
      "e7c585b12e764902a0d22ae5841f8f05",
      "b3feb1bc49fb46c582a3fe2d97651c05",
      "a4768b201e0e4b4b95abac910e026d32",
      "e150965861f0436a9038474315c54d40",
      "5f8e8d49eab24a6793c18c22bdcafda6",
      "d1a0f0f41e5544118e76c26a0d93c39e",
      "f14fe029b1fd44b29e6bfbac307a29ba",
      "7544805bdceb4cceba4b6c540efcc8c0",
      "99ca0bb7d0c84b809f6c94559077e562",
      "4339b9fdfdeb429ab24522596be25fc5",
      "da29def135d346f7b813adfcb9b5be9d",
      "8bff6c8f20ce4057a0d4b6d589447d9e",
      "326ee715fcc241139a754516906006a0",
      "3245baf8dac545668bc1c6d3b8b5f747",
      "8a1d4efcdc4c4645bc5c43e8ff5d3557",
      "d7e26a0555824f0695dcf8a724f9bfb1",
      "f79a120a28244b4080cb2d66a178b017",
      "1bd1e311b7b94028baca53ee42a530b7",
      "ae155b1e2be04ffa8d6ce74fd3a7ffb0",
      "38e2b62fb14a4077acdd427529f7be1f",
      "46fd8f3e945f4a238c6565f5dd0e8008",
      "b22025b719bb4432b50f55a58d0166d3",
      "4dd1538a0c31440994a0bcbfcb12b6cb",
      "b4ec7a75f42d48499a0e99ef0b8941d0",
      "28b9dabe3ba843179fac0bf28f59c866",
      "f5dec83b3351467194a29cb6841e525c",
      "d8f2c223fb77415c9eee2b81e2d11b7d",
      "ba50eb6258f24c3390e488fc0662f230",
      "a418bcb2c3744ba092f0eaf5664fb3e4",
      "08854fefe005402599c9a21fb5378f9d",
      "8118cbd5a3fe481d9ea844b35d25f3fe",
      "fc2440dbd8ac4ff684bd3c7530bf8af8",
      "bd818b81650c47058361662f7ad18cd3",
      "902ebc4390b94d76b6fe1ca6d7234d08",
      "76df97f50ffd4a57bba274c73894eb00",
      "3e5e6255b2094c53875a65fbb1ea51c4",
      "97ac216a48344aee99edebdaf80b56b8",
      "3acad0941d2b44e5a37ae338a0f4472f",
      "762ba1b5530b42e088a2b6b9b464b3e9",
      "a7399b8d78854b149412d27b6807647b",
      "3945156c202a4a2ba58e33e31e133fef",
      "4465df5ecc334265aec0e6f6e14bc531",
      "ef6882ccd767456c831c2709b8b0ae49",
      "205e84bc73804d58a26d556add709c91",
      "90a487272d6d422f90c176fb418b598f",
      "88798e13496541ff9c61dda5ddde853d",
      "51a22a44994746c1830735cd45a0f5da",
      "50f879fe2dfd411180534d560ee9066f",
      "03f0c751e5f84bd586be7e2480fb44e7",
      "4c0c25f97096467aaf1b481f24d3767e",
      "bcd7bb2e292e4725b84b3f8ac1286d49",
      "e203d1fe54d44162b8205975af07a9a4",
      "6ef424a3bc4e40aab94b390aa0b59fc7",
      "bb549c2fb00d40058ca529fdee8752bc",
      "d7e0ae7f0c024185b41290d03cfec944",
      "22257c7f013e4a91a89eb88e31f53fb3",
      "7b692a1e735c43d9927be5a48fdd5705",
      "b11a097f8d534e12959a40400fbed6c5",
      "8c8d2f13f10d41b2a0126172ada44165",
      "04273ffbe0f746e39e2832aeb78573d3",
      "d597d10965ea4679baaf0bea5a9c1466",
      "600084d783884a8fbeff78f0738bcd03",
      "1f5a4d0be275440b8084fed5d06680f8",
      "5e192c084e494da2b8a4434954a53c1b",
      "def3e9d8d3434fe4811b099c4109c2d7"
     ]
    },
    "collapsed": true,
    "id": "7FL0SyO5zqqc",
    "outputId": "97a540e1-c9b6-4c5d-90be-11a1bd081c60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad74d5912e04619930e0cc08ce8f39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ea35e6572947e1ae2f701f533ec084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e47c19a11554cea9b93f0e2c3666776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e0c6b5034741d8b461a1cbf3ce05ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b828a9f4d64b9d9e2fcb688cee3514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0d5106a76f4a4a9a7c6ee860a3c2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da29def135d346f7b813adfcb9b5be9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22025b719bb4432b50f55a58d0166d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd818b81650c47058361662f7ad18cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205e84bc73804d58a26d556add709c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e0ae7f0c024185b41290d03cfec944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YJMnb5uV3t2E",
    "outputId": "8a70ae1e-0ffa-464c-f31a-749fddcd0f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 297\n",
      "\n",
      "First 5 records:\n",
      "\n",
      "Record 1:\n",
      "{\n",
      "  \"role\": \"employee\",\n",
      "  \"question\": \"How much monthly food allowance do junior employees receive?\",\n",
      "  \"relevant_chunk_ids\": [\n",
      "    \"PAYROLL_&_BENEFITS_DOCUMENT_Employee_Benefits_parent_0\"\n",
      "  ],\n",
      "  \"test_role\": \"hr\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Record 2:\n",
      "{\n",
      "  \"role\": \"employee\",\n",
      "  \"question\": \"Is meal card allowance tax exempt?\",\n",
      "  \"relevant_chunk_ids\": [\n",
      "    \"PAYROLL_&_BENEFITS_DOCUMENT_Employee_Benefits_parent_0\"\n",
      "  ],\n",
      "  \"test_role\": \"hr\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Record 3:\n",
      "{\n",
      "  \"role\": \"employee\",\n",
      "  \"question\": \"What is the internet reimbursement limit for work from home?\",\n",
      "  \"relevant_chunk_ids\": [\n",
      "    \"PAYROLL_&_BENEFITS_DOCUMENT_Employee_Benefits_parent_1\"\n",
      "  ],\n",
      "  \"test_role\": \"hr\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Record 4:\n",
      "{\n",
      "  \"role\": \"employee\",\n",
      "  \"question\": \"Does health insurance cover parents?\",\n",
      "  \"relevant_chunk_ids\": [\n",
      "    \"PAYROLL_&_BENEFITS_DOCUMENT_Employee_Benefits_parent_2\"\n",
      "  ],\n",
      "  \"test_role\": \"hr\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "Record 5:\n",
      "{\n",
      "  \"role\": \"employee\",\n",
      "  \"question\": \"What expenses are NOT covered under LTA?\",\n",
      "  \"relevant_chunk_ids\": [\n",
      "    \"PAYROLL_&_BENEFITS_DOCUMENT_Employee_Benefits_parent_2\"\n",
      "  ],\n",
      "  \"test_role\": \"hr\"\n",
      "}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "FILE_PATH = \"/content/rbac_eval.jsonl\"\n",
    "\n",
    "records = []\n",
    "\n",
    "with open(FILE_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        records.append(json.loads(line))\n",
    "\n",
    "print(f\"Total records: {len(records)}\")\n",
    "\n",
    "print(\"\\nFirst 5 records:\\n\")\n",
    "for i, record in enumerate(records[:5], start=1):\n",
    "    print(f\"Record {i}:\")\n",
    "    print(json.dumps(record, indent=2))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PFi6IVJyzqnC"
   },
   "outputs": [],
   "source": [
    "def run_rag(role: str, question: str):\n",
    "\n",
    "    query_dense = emb.embed_query(question)\n",
    "    query_sparse = bm25.encode_queries([question])[0]\n",
    "\n",
    "    results = index.query(\n",
    "        vector=query_dense,\n",
    "        sparse_vector=query_sparse,\n",
    "        top_k=5,\n",
    "        include_metadata=True,\n",
    "        filter={role: {\"$eq\": True}}\n",
    "    )\n",
    "\n",
    "    if not results.matches:\n",
    "        return []\n",
    "\n",
    "    filtered = [\n",
    "        m for m in results.matches\n",
    "        if m.score >= PINECONE_SCORE_THRESHOLD\n",
    "    ]\n",
    "\n",
    "    if not filtered:\n",
    "        return []\n",
    "\n",
    "    filtered.sort(key=lambda x: x.score, reverse=True)\n",
    "\n",
    "    final = []\n",
    "    for m in filtered[:TOP_K]:\n",
    "        final.append({\n",
    "            \"doc_id\": m.metadata.get(\"parent_id\"),\n",
    "            \"chunk\": m.metadata.get(\"text\"),\n",
    "            \"pinecone_score\": m.score\n",
    "        })\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGFXBOqUzyCl",
    "outputId": "ecbc3e95-1012-4682-83ca-f02e55c9efd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” RBAC SECURITY EVALUATION\n",
      "========================================\n",
      "Total attack tests   : 297\n",
      "Violations found    : 0\n",
      "Violation rate      : 0.0000\n",
      "Critical (Rank 1)   : 0\n",
      "Medium (Rank >1)    : 0\n",
      "========================================\n",
      "\n",
      "âœ… No RBAC leaks detected\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "RBAC_FILE = \"/content/rbac_eval.jsonl\"\n",
    "TOP_K = 5\n",
    "PINECONE_SCORE_THRESHOLD = 0.5\n",
    "\n",
    "def load_data(path: str) -> List[Dict]:\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_doc_type(doc_id):\n",
    "    if doc_id.startswith(\"PAYROLL_&_BENEFITS_DOCUMENT\"):\n",
    "        return \"payroll\"\n",
    "    if doc_id.startswith(\"hr_policy_documents\"):\n",
    "        return \"hr_policy\"\n",
    "    if doc_id.startswith(\"EMPLOYEE_LIFECYCLE_DOCUMENT\"):\n",
    "        return \"lifecycle\"\n",
    "    if doc_id.startswith(\"COMPANY-SPECIFIC_DOCUMENT\"):\n",
    "        return \"company\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def is_violation(doc_id, test_role):\n",
    "    dtype = get_doc_type(doc_id)\n",
    "\n",
    "\n",
    "    access_rules = {\n",
    "        \"payroll\": [\"employee\", \"manager\"],\n",
    "        \"hr_policy\": [\"employee\"],\n",
    "        \"lifecycle\": [\"manager\"],\n",
    "        \"company\": [\"hr\"]\n",
    "    }\n",
    "\n",
    "    allowed_roles = access_rules.get(dtype, [])\n",
    "    return test_role not in allowed_roles\n",
    "\n",
    "\n",
    "def evaluate_rbac():\n",
    "    data = load_data(RBAC_FILE)\n",
    "\n",
    "    total = 0\n",
    "    violations = 0\n",
    "    critical = 0\n",
    "    medium = 0\n",
    "\n",
    "    failure_cases = []\n",
    "\n",
    "    for row in data:\n",
    "        question = row[\"question\"]\n",
    "        test_role = row[\"test_role\"]\n",
    "        expected_doc = row[\"relevant_chunk_ids\"][0]\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        retrieved = run_rag(test_role, question)\n",
    "\n",
    "        for rank, r in enumerate(retrieved, start=1):\n",
    "            doc_id = r[\"doc_id\"]\n",
    "\n",
    "            if is_violation(doc_id, test_role):\n",
    "                violations += 1\n",
    "\n",
    "                if rank == 1:\n",
    "                    critical += 1\n",
    "                else:\n",
    "                    medium += 1\n",
    "\n",
    "                failure_cases.append({\n",
    "                    \"question\": question,\n",
    "                    \"test_role\": test_role,\n",
    "                    \"leaked_doc\": doc_id,\n",
    "                    \"rank\": rank,\n",
    "                    \"doc_type\": get_doc_type(doc_id)\n",
    "                })\n",
    "                break\n",
    "\n",
    "    violation_rate = violations / total if total else 0\n",
    "\n",
    "    print(\"\\nğŸ” RBAC SECURITY EVALUATION\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total attack tests   : {total}\")\n",
    "    print(f\"Violations found    : {violations}\")\n",
    "    print(f\"Violation rate      : {violation_rate:.4f}\")\n",
    "    print(f\"Critical (Rank 1)   : {critical}\")\n",
    "    print(f\"Medium (Rank >1)    : {medium}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    if failure_cases:\n",
    "        print(\"\\n--- SAMPLE LEAK CASES ---\")\n",
    "        for case in failure_cases[:5]:\n",
    "            print(json.dumps(case, indent=2))\n",
    "    else:\n",
    "        print(\"\\nâœ… No RBAC leaks detected\")\n",
    "\n",
    "    return {\n",
    "        \"total_tests\": total,\n",
    "        \"violations\": violations,\n",
    "        \"violation_rate\": violation_rate,\n",
    "        \"critical\": critical,\n",
    "        \"medium\": medium\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_rbac()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
